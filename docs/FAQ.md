# FAQ

OpenSAMM Benchmarking Improvement Project:  Frequently Asked QuestionsA.	How can I participate in the OpenSAMM benchmarking improvement effort?There are several important ways you can participate in the benchmarking improvement effort.  Although the initial contingent of application security leaders worked closely to put together the enhanced framework, it has always been the intention to expand the number of contributors, and by doing so, expand the amount of publicly available data for software teams to review.   For example, one of the next steps after the Dublin OpenSAMM Summit in March 2015 is to create a process for sponsorship for additional contributing organizations.  If you are interested in volunteering for any aspect of the OpenSAMM project, don’t hesitate to reach out to the project leads who will point you in the right direction.In the short-term, there are several ways to participate in the benchmarking effort1.	If you have had an SDLC assessment of your development team(s) or organization conducted by a third-party, grant permission for your data to be used and ask the assessor to add your data to the benchmarking repository.2.	Conduct a self-assessment and submit the results to the benchmarking repository.  There will eventually be a website that will allow you to post your anonymized results.3.	Volunteer to contribute any aspect of the data collection and validation process improvement effort.  There is not a shortage of work, and the progress made up to this point has been a result of heavy lifting by a lot of talented appsec enthusiasts. It’s been a contribution-driven effort and there is certainly no shortage of work.  Ask one of the project leads or contributing organizations where your help might be best needed.B.	How accurate will the benchmarking data be?Accurate, and more so as more data is contributed… Quality of inputs has been a focus from the outset.   Given that numerous organizations will be contributing data, as opposed to one, guidance is being developed to define the required minimum level of knowledge of those contributing data.   The initial contingent of contributors, which included many of the leading application security firms, essentially “peer certified” each other, based upon years of reputation in the market and mutual respect  Ultimately, there may be different levels of assurance of data inputs.  For example, self-assessed results may be tagged to identify a lower level of confidence.  This is an aspect of the project that we characterize as a work in progress, and an opportunity for further technical leadership and volunteer input.C.	How should we use the information from the software security improvement initiative?At a high level, the information should be used to see how your software teams are doing relative to other teams in other organizations. At a more tactical level, it will allow you to identify which sets of software security activities you are doing relative to other teams.  This should identify certain gaps and provide benchmarking data that provides insight from outside your organization.   The underlying assumption here is that many organizations are doing a subset of ideal software security activities, or maybe not doing certain activities at all.  The OpenSAMM information will allow all organizations to confirm this, add or change the mix of activities, which in turn will generally improve the state of software security in that organization.   By providing the framework and data that all can access, OWASP has an opportunity to provide an asset that can be used across countries and industries and generally change how software security is approached.D.	What assurance is there about anonymity?The software security data that is available for benchmarking purposes has been intentionally anonymized in order to protect the source of the data.  Only the data steward (the application security vendor who did the assessment, not OpenSAMM) will know the relationship between the data set and the provider of the information.  This is an important aspect of the improvement effort, given the sensitivity of the topic and data to potential contributors.  Typically, large organizations that have multiple software development teams and would be great sources of data, are reluctant to provide information on security and software techniques given the obvious risk of attackers using that against them.As a result, the contributing organizations put in a tremendous amount of energy into solving this problem.  What came out of that process is a one-way data flow that involves a trust  relationship between data sources, what we are calling “data stewards,” and the OWASP OpenSAMM data repository.   As previously discussed, the data source is the organization that contributes results, typically to a data steward.  The data steward is organization that has a contractual relationship between itself and the data source, initially a set of trusted application security vendors.  In the context of this initial effort, the data stewards were the application security vendors that contributed (e.g., Aspect, Gotham, Veracode, AsTech, etc.)  That contract defines confidentiality terms that provide the data sources reasonable assurance that their anonymity will be maintained.   In addition, the data stewards have a vested interest to continue to protect that anonymity given their contracts, reputation, and future hopes of maintaining a positive relationship with their data source partners.In addition, “categorizations” have been used for certain attributes in order to obfuscate certain data sources.  This will prevent the cleverest amongst us from identifying certain companies based upon geographic or business attributes.  Of note, each organization will be assigned a unique reference identifier to allow them to be able to identify their particular data in the open dataset, which will allow them to query their own data.  This will allow the data source to query their data, as well as to provide the option to use other collection partners and note feel compelled to use a particular vendor should they choose not to do so.E.	Why is OpenSAMM the right reference to benchmark against?The OpenSAMM itself is a maturity model, rather than a process model or survey result. It is a free, widely available application architecture that is independent, vendor agnostic and has been translated into multiple languages. It is widely known and has the support of a very large number of people working in application security and software development. However, with the data contributed as part of this effort, organizations will be able to conduct certain benchmarking efforts with the activities laid out in OpenSAMM, combined with the data provided by numerous data sources.F.	Will it be possible to query all attributes stored in the repository?Yes. The intention is to make the anonymized data publicly available in the near-term, so that organizations can compare themselves with their peers by size, industry vertical, number of developers, etc. However, only generalized attributes about a company will be stored in the open dataset to prevent the “reverse engineering” activities to identify data sources of the individual organizations. G.	My company is using another model/standard. Can we still benefit from the scheme?Mappings to common information security, application security, and compliance frameworks are in development. However, some of these are not specific enough for application security and there will be gaps in the information if you have not used an application-specific model like OpenSAMM.  This is an opportunity for additional volunteer help for those interested.H.	We are a small software development company (1-2 developers).  Can I participate by providing data to the benchmarking initiative?Yes!  We encourage all sizes and types of organizations to participate.  As the database grows, it allows for a more comprehensive comparison of your organization’s results to the data.I.	How does this OpenSAMM benchmarking effort compare with BSIMM or SAFECode?All three activities have the same goal in mind, which is to improve the state of software security across all the organizations.  Throughout that process the team members kept that in mind, given the very human nature to compare.  To be candid though, as a capability maturity model, they are similar and no doubt share a common lineage.   Each provides a structured approach and process to conduct software security capability maturity assessments.  The key differentiators of the OpenSAMM Improvement is scale, guidance, and open access to the data.   The OpenSAMM benchmarking improvement efforts will provide an open and public data source that will quickly expand in number, making it a statistically sound and better measure for organizations to benchmark against.  In addition, OpenSAMM is an OWASP initiative, with a consortium of security leaders, providing prescriptive guidance based on hundreds of years of practiced experience.   Call it a crowd sourced model if you may, but we think it will provide tremendous value and insight for those not currently using a maturity framework to improve their state of software security.J.	How is the OpenSAMM Benchmarking Improvement collection approach different from other models?In any subjective survey and interview process, there is the possibility of a range of interpretation, even if individuals from a single company perform the assessments.  One of the foundational goals of OpenSAMM and this evolution is to minimize inconsistency to the greatest extent possible.In the OpenSAMM benchmarking effort, the data collected can be done by either application security professionals or from self-assessments. Application security professionals should have years of experience to help provide an accurate assessment of the maturity of a team or organization. When querying the data, the different sources will be selectable and/or identified. This helps ensure the understanding of whether or not the data is from a self-assessment or from an industry professional.There is value in knowing what organizations are currently doing, but every organization is different and has different goals.  So just because one organization is doing “X” doesn’t mean that every similar organization should be doing “X”.  Additionally, BSIMM focuses on what current practices are without regard to the effectiveness of those practices.  It is left up to the judgment of the reader to form their own opinions as to the efficacy of those security practices.  On the other hand, prescriptive recommendations can be very helpful to organizations that are new to software security or need guidance in deciding what types of activities tend to produce secure software.  The prescriptive recommendations in OpenSAMM emphasize software security practices that have been deemed impactful by software security experts, and help to produce secure software in a consistent manner.K.	How was the benchmark data collected?The initial benchmark data set was seeded with the results of software security initiatives conducted by the various members of an industry consortium of leading application security firms.  Each of these firms have assessed and analyzed software security initiatives of many organizations in a variety of vertical markets.  With the permission of the assessed organizations, the firms collected data, removed any identifying information and submitted the assessment results to the OpenSAMM Benchmarking project.L.	Will an organization be able to periodically re-assess itself to see changes over time?An organization will be able to periodically re-assess themselves in order to measure their current status.  Periodic re-measurement is an excellent way to measure changes in your software development processes to look for both improvements and for areas that need additional work.  Depending on the organization, it is generally best to do subsequent assessments annually or semi-annually to avoid “assessment fatigue” and in order to allow sufficient time to observe real changes.M.	What’s in it for us? (Why would an organization want to contribute benchmarking data?) Benchmarking helps organizations get insight into how they perform relative to other similar organizations of the same profile.  Benchmarking results combined with profiled prescriptive guidance will help to identify areas where additional effort and investment can benefit. The guidance will help prioritize areas of improvement, monitor the software development team’s performance, and manage the change.N.	Where can I download the data?When the data becomes available, it will be hosted on the OpenSAMM website.O.	Where can I get a copy of OpenSAMM?The OpenSAMM Software Assurance Maturity Model website has the current version of the OpenSAMM framework.P.	What is the licensing for the benchmarking data?Use of the OpenSAMM information is subject to use under the Creative Commons license: http://creativecommons.org/choose/Q.	Which security organizations are initially participating in this effort?•	Aspect Security•	AsTech Consulting•	Denim Group, Ltd. •	Gotham Digital Services•	OWASP•	Security Innovation•	VeracodeR.	Should we consider this Benchmarking Improvement effort to effectively be OpenSAMM 2.0.?No.  It was our goal to contribute an improved data scheme and data, to provide an added boost to the OpenSAMM project.  We’d be honored if much of that work were included in a 2.0 release sometime in the not-too-distant future.